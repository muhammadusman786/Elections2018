{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Acquisition \n",
    "## The Purpose of this kernel is to illustrate the use of BeautifulSoup to Scrap Elections Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's write script to scrap NA 2008 Data\n",
    "import requests\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "page = requests.get('https://ecp.gov.pk/ResultDetails.aspx?EleId=1&Election=General%20Election%2018%20Feb%202008')\n",
    "contents = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import beautiful soup to get things started\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of Urls that list result of each constituency\n",
    "list_urls = []\n",
    "for link in soup.find_all('tr'):\n",
    "    extracted_row = link.find('a')\n",
    "    if extracted_row is not None:\n",
    "        list_urls.append(\"https://ecp.gov.pk/\"+extracted_row.get('href'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://ecp.gov.pk/ConstResult.aspx?Const_Id=NA-1 &type=NA',\n",
       " 'https://ecp.gov.pk/ConstResult.aspx?Const_Id=NA-2 &type=NA',\n",
       " 'https://ecp.gov.pk/ConstResult.aspx?Const_Id=NA-3 &type=NA',\n",
       " 'https://ecp.gov.pk/ConstResult.aspx?Const_Id=NA-4 &type=NA',\n",
       " 'https://ecp.gov.pk/ConstResult.aspx?Const_Id=NA-5&type=NA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's have a peek at the list\n",
    "list_urls[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_first_table_content(soup):\n",
    "    #first table provides information about registered votes, votes polled, valid votes, rejected votes and turnout\n",
    "    first_table = soup.select_one(\"table:nth-of-type(1)\")\n",
    "    all_rows = first_table.find_all('tr')\n",
    "    first_table_list = []\n",
    "    #first table list contains rows of first table, because each row represent's different entity\n",
    "    #i.e. votes, votes polled, valid votes, rejected votes and turnout\n",
    "    for row in all_rows:\n",
    "        extractedEntity = row.select_one(\"td:nth-of-type(2)\")\n",
    "        if(extractedEntity is not None):\n",
    "            first_table_list.append(extractedEntity.find('p').find('span').contents[0])\n",
    "            \n",
    "    return first_table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_second_table_content(soup, first_table_list):\n",
    "    #second table contain candidate results in a constituency\n",
    "    second_table = soup.select_one(\"table:nth-of-type(2)\")\n",
    "    all_rows_second = second_table.find_all('tr')\n",
    "    \n",
    "    for row in all_rows_second:\n",
    "        if(row is not None):\n",
    "            extracted_col1,extracted_col2,extracted_col3 = row.select_one(\"td:nth-of-type(1)\"),\\\n",
    "                            row.select_one(\"td:nth-of-type(2)\"),row.select_one(\"td:nth-of-type(3)\")\n",
    "            candidate_name = extracted_col1.find('p').contents[0] if(extracted_col1 is not None) else None\n",
    "            party = extracted_col2.find('p').contents[0] if(extracted_col2 is not None) else None\n",
    "            votes = extracted_col3.find('p').contents[0] if(extracted_col3 is not None) else None\n",
    "            if(candidate_name is not None and party is not None and votes is not None):\n",
    "                # first_table_list contains votes, votes polled, valid votes, rejected votes and turnout\n",
    "                # not naming them here separtely to save time\n",
    "                list_of_tuples.append((district,constituency,candidate_name,party,votes,first_table_list[2],\\\n",
    "                             first_table_list[3],first_table_list[1],first_table_list[0],first_table_list[4]))\n",
    "    return list_of_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for some heavy lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a session by visting primary_url first, otherwise the site will redirect us to other page\n",
    "#which is not of our interest\n",
    "primary_url = \"https://ecp.gov.pk/ResultDetails.aspx?EleId=1&Election=General%20Election%2018%20Feb%202008\"\n",
    "session = requests.Session()\n",
    "temporary_result = session.get(primary_url)\n",
    "\n",
    "# Let's iterate the links and create a list of tuples\n",
    "list_of_tuples = []\n",
    "for url_item in list_urls:\n",
    "    page = session.get(url_item)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    # time to get district name and constituency\n",
    "    heading = soup.find('p').find('span').contents[0]\n",
    "    district = heading[heading.find(\"(\")+1:heading.find(\")\")]\n",
    "    constituency = heading.split(\" \")[0]\n",
    "    \n",
    "    #first table provides information about registered votes, votes polled, valid votes, rejected votes and turnout\n",
    "    first_table_list = scrap_first_table_content(soup)\n",
    "    #second table contain candidate results in a constituency\n",
    "    list_of_tuples = scrap_second_table_content(soup, first_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kech-cum-Gwadar.',\n",
       "  'NA-272',\n",
       "  'Dr. Muhammad Haider Baloch',\n",
       "  'Pakistan Peoples Party Parliamentarians',\n",
       "  '3514',\n",
       "  '107930',\n",
       "  '3992',\n",
       "  '106936',\n",
       "  '316766',\n",
       "  '33.75 %'),\n",
       " ('Kech-cum-Gwadar.',\n",
       "  'NA-272',\n",
       "  'Mufti Ahtisham-ul-Haq Asia Abadi',\n",
       "  'MUTTHIDA\\xa0MAJLIS-E-AMAL\\xa0PAKISTAN',\n",
       "  '1237',\n",
       "  '107930',\n",
       "  '3992',\n",
       "  '106936',\n",
       "  '316766',\n",
       "  '33.75 %'),\n",
       " ('Kech-cum-Gwadar.',\n",
       "  'NA-272',\n",
       "  'Syed Sher Jan. (R)',\n",
       "  'Independent',\n",
       "  '1520',\n",
       "  '107930',\n",
       "  '3992',\n",
       "  '106936',\n",
       "  '316766',\n",
       "  '33.75 %'),\n",
       " ('Kech-cum-Gwadar.',\n",
       "  'NA-272',\n",
       "  'Yaqoob Bizenjo.',\n",
       "  'Balochistan National Party (Awami)',\n",
       "  '61655',\n",
       "  '107930',\n",
       "  '3992',\n",
       "  '106936',\n",
       "  '316766',\n",
       "  '33.75 %'),\n",
       " ('Kech-cum-Gwadar.',\n",
       "  'NA-272',\n",
       "  'Zubeda Jalal',\n",
       "  'Independent',\n",
       "  '33564',\n",
       "  '107930',\n",
       "  '3992',\n",
       "  '106936',\n",
       "  '316766',\n",
       "  '33.75 %')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuples[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the number of records in our dataset\n",
    "len(list_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seems like you don't like tuples, go ahead and make dataframe near and dear to your heart\n",
    "columns = ['Seat','ConstituencyTitle','CandidateName','Party','Votes','TotalValidVotes','TotalRejectedVotes','TotalVotes','TotalRegisteredVoters','Turnout']\n",
    "df = pd.DataFrame([x for x in list_of_tuples], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# want to save data, specify the path\n",
    "writer = pd.ExcelWriter('../NA13.xlsx')\n",
    "df.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
