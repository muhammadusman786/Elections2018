{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\nfrom subprocess import check_output\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Lets Use the Initial Cleaning script written by Zeeshan and move on to interesting analysis and Insights  "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d282c4ee9b10838a0c134dc692f1eada0d3d1030"
      },
      "cell_type": "code",
      "source": "# this cell is zeeshan's script for intial cleaning\n# Read data\nNA2 = pd.read_csv(\"../input/National Assembly 2002 - Updated.csv\", encoding = \"ISO-8859-1\")\nNA8 = pd.read_csv(\"../input/National Assembly 2008.csv\", encoding = \"ISO-8859-1\")\nNA13 = pd.read_csv(\"../input/National Assembly 2013.csv\", encoding = \"ISO-8859-1\")\n\n# rename coloumns\nNA8.rename(columns={'Unnamed: 0':'District'}, inplace=True)\nNA13.rename(columns={'Unnamed: 0':'District'}, inplace=True)\n\n#Get districts separated out of seats\nNA8.District = NA8.Seat.str.split(\"-\", expand=True)[0]\nNA13.District = NA13.Seat.str.split(\"-\", expand=True)[0]\n\n#Change Data type of turnout\nNA8['Turnout'] = NA8['Turnout'].str.rstrip('%').str.rstrip(' ')\nNA13['Turnout'] = NA13['Turnout'].str.rstrip('%').str.rstrip(' ')\nNA8['Turnout'] = pd.to_numeric(NA8['Turnout'], errors='coerce')\nNA13['Turnout'] = pd.to_numeric(NA13['Turnout'], errors='coerce')\n\n#Add Year Column\nNA2['Year'] = \"2002\"\nNA8['Year'] = \"2008\"\nNA13['Year'] = \"2013\"\n\n#Rename coloumns in NA2\nNA2.rename(columns={'Constituency_title':'ConstituencyTitle', 'Candidate_Name':'CandidateName', 'Total_Valid_Votes':'TotalValidVotes',\n                    'Total_Rejected_Votes':'TotalRejectedVotes', 'Total_Votes':'TotalVotes', 'Total_Registered_Voters':'TotalRegisteredVoters', }, inplace=True)\n\n#Concat all results\ndf = pd.concat([NA2, NA8, NA13])\n\ndf['District'] = df['District'].str.lower()\n# remove trailing white spaces\ndf['District'] = df['District'].str.strip()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ddeeb7e9eaf600e92395aca72b8f1765b2d6fec8"
      },
      "cell_type": "markdown",
      "source": "## Let's clean textual columns before moving to the fun part"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d45999f9c3dd9841088779157b1338a4dbd408d7"
      },
      "cell_type": "code",
      "source": "#convert textual content to lower case\ndf['CandidateName'] = df['CandidateName'].str.lower()\ndf['Party'] = df['Party'].str.lower()\n# remove trailing white spaces\ndf['CandidateName'] = df['CandidateName'].str.strip()\ndf['Party'] = df['Party'].str.strip()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "80f11263921ba3af7f88c75711f8791b9026473c"
      },
      "cell_type": "code",
      "source": "# Let's write a function to filter parties which fuzzy wuzzy thinks are same but actually they are not\n# Parties like Pakistan Muslim League(n),Pakistan Muslim League(qa),Pakistan Muslim League(q) and Pakistan Muslim League will have high similarity scores \ndef filter_similarity_exceptions(party_to_match,party_list):\n    #find sub party name\n    sub_party = party_to_match[party_to_match.find(\"(\")+1:party_to_match.find(\")\")].strip()\n    \n    # if party_to_match has no sub party, filter out parties with sub party from party_list\n    if(len(party_to_match.split('(')) < 2):\n        party_list = [x for x in party_list if len(x.split('(')) < 2]\n    \n    #make sure sub party names upto length 2 are same, because they can fall in specified similarity score threshold \n    if(len(sub_party) <= 2):\n        party_list = [x for x in party_list if x[x.find(\"(\")+1:x.find(\")\")].strip() == sub_party]\n    \n    return party_list",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fc906621ecab7c39c8df16c14c737b081cd6f7ea"
      },
      "cell_type": "code",
      "source": "# modification of function written by zeeshan to filter similarity exceptions\ndef replace_matches_in_party(df,string_to_match, min_ratio = 90, column='Party'):\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # get the top 10 closest matches to our input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # only get matches with a ratio > 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n    \n    #filter similarity exceptions\n    close_matches = filter_similarity_exceptions(string_to_match,close_matches)\n    \n    # get the rows of all the close matches in our dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e2952164d55593dd6db3a3f05612c26578036c61"
      },
      "cell_type": "code",
      "source": "# iterate unique parties and replace the same parties which are spelled differntly\nfor party in df['Party'].unique():\n    replace_matches_in_party(df,party, min_ratio = 93, column='Party')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6355d0526f59de28ebff0f1e4844eaab5a53a620",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# have a look at the results after sorting\ncandidates = df.sort_values('Party')['Party'].unique()\nprint(candidates)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "29b1bab581c82923445f9d099dc459779034b1f6"
      },
      "cell_type": "code",
      "source": "# Ah it's look like, if we decrease the threshold(min_score) further it may cause problems\n# I know these parties have addition of words like Pakitan and Party but are similar, let's replace them\ndf['Party'].replace(['muttahida qaumi movement pakistan'], 'muttahida qaumi movement', inplace = True)\ndf['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\ndf['Party'].replace(['indeindependentdente','independent (retired)','indepndent'], 'independent',inplace = True)\ndf['Party'].replace(['muttahidda majlis-e-amal pakistan','mutthida\\xa0majlis-e-amal\\xa0pakistan'\n                     ,'mutthidaï¿½majlis-e-amalï¿½pakistan'] \n                     ,'muttahidda majlis-e-amal' ,inplace = True)\ndf['Party'].replace(['nazim-e-mistafa'], 'nizam-e-mustafa party' ,inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33be52baa78b318bc2d1712202a51d52e1914bb3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# we are all set to meet winners\n#reset the index \ndf.reset_index(inplace = True)\n#find candidates with max votes in a constituency and year, aka the winners\nwinning_candidates = df.loc[df.groupby(['Year','ConstituencyTitle'])['Votes'].idxmax()].sort_values('ConstituencyTitle')\nwinning_candidates.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e5213be82e75dc124b679647a098dd00a37826b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# let's find year wise number of seats won by each party \nyear_wise_party_results = winning_candidates.groupby(['Party','Year']).size().to_frame('count').sort_values('count')\nyear_wise_party_results.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6a6bb910b2c8b4776c9fa5bfe1d23bd0e4ecba3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# find number of times a candidate won from the same constituency\nconstituency_wise_candidate_wins = winning_candidates.groupby(['ConstituencyTitle','CandidateName']).size().to_frame('wins')\nconstituency_wise_candidate_wins.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da4af0139fddd2cfb974f89a311fab55aadbc5b2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# find candidates who won atleast twice from the same constituency\nstrong_candidates = constituency_wise_candidate_wins[constituency_wise_candidate_wins['wins'] >=2 ].sort_values('wins', ascending = False)\nstrong_candidates.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53b0853eb302f14460f64710afc1b515741d2775",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# find  of number of times a party won from the same constituency\nconstituency_wise_party_wins = winning_candidates.groupby(['ConstituencyTitle','Party']).size().to_frame('wins')\n#find constittuencies where same party won in all three elections\nconfirmed_constituencies_by_party = constituency_wise_party_wins[constituency_wise_party_wins['wins'] == 3].sort_values('wins', ascending = False)\nconfirmed_constituencies_by_party.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6cca705600b6347105cbacd4c26d0395783f975",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Swing constituencies are those where maximum wins by the same party are 1 i.e. where no party won twice\n#First we will find constituency wise maximum number of wins by a party \nconstituency_wise_max_party_wins = constituency_wise_party_wins.groupby(['ConstituencyTitle'])['wins'].max().to_frame('max_wins_by_any_party')\n#filter out those constituencies where max wins by any party is 1\nswing_constituencies = constituency_wise_max_party_wins[constituency_wise_max_party_wins['max_wins_by_any_party'] == 1]\nswing_constituencies.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4e19121bd607ecf9b238f712582650ef40e85af",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Time to find Lotas, Ah ha (candidates who changed their parties while competing from the same constituency)\nnum_parties_by_candidate = df[['CandidateName','ConstituencyTitle','Party']].groupby(['CandidateName','ConstituencyTitle'])['Party'].nunique()\\\n.to_frame('count').sort_values('count', ascending = False)\n#find candidates with party count greater than 1\nlotas = num_parties_by_candidate[num_parties_by_candidate['count'] > 1]\n#some lotas for you\nlotas.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d45a6217efac3b012d2e0166ce89d4e08aab022",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# first value in a constituency may have a null value, let's fill it with next value from same constituency and year\ndf['Turnout'] = df.groupby(['ConstituencyTitle','Year'])['Turnout'].fillna(method = 'bfill')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e86ce7497b36ed37916ba55eb0c8bfab513e1e0c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# find min, max , average turnout and valid votes constituency wise\naggregations_by_constituency = df.groupby('ConstituencyTitle').agg({'TotalValidVotes' : [np.max, np.min, np.average ],'Turnout' : [np.max, np.min, np.average]})\naggregations_by_constituency.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92fc01654d286636f158d8870b4ea01ad39e8a49",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# now we will find total number of votes casted to all parties(year wise) and sort them to see popular vote winners\npopular_vote_winners = df.groupby(['Party', 'Year'])['Votes'].sum().to_frame('total_votes').sort_values('total_votes', ascending = False)\npopular_vote_winners.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a3e97bb7dded7eb03311405a667884228f5ec93b"
      },
      "cell_type": "markdown",
      "source": "## That's all for today, building visualizations on top of these insights might be an interesting idea for you"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2ec6ca9c6191f3d0a360b8fcdf77fc84e8f66217"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}